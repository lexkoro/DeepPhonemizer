
paths:
  checkpoint_dir: /workspace/pretrained_models/g2p/forward_checkpoints_v3   # Directory to store model checkpoints and tensorboard, will be created if not existing.
  data_dir: /workspace/pretrained_models/g2p/forward_datasets_v3            # Directory to store processed data, will be created if not existing.

preprocessing:
  languages: ['tur',
 'slk',
 'ltz',
 'spa-la',
 'ukr',
 'fra',
 'spa-ca',
 'deu',
 'dan',
 'lit',
 'nld',
 'ron',
 'fin',
 'por-po',
 'ita',
 'rus',
 'eng-uk',
 'pol',
 'slv',
 'mkd',
 'eng-us',
 'hun',
 'por-bz',
 'ces']  # All languages in the dataset.

  # Text (grapheme) and phoneme symbols, either provide a string or list of strings.
  # Symbols in the dataset will be filtered according to these lists!
  text_symbols: "čǁц7Șȃ₂џŚrèĆëȅBƵљőЧъЇѓÕÂЬ'ЙąШéщѳѣИĐÉøİХѵёьТєDāзºbîŘњGеЌğnðЖŻŰҐнЅńбФúšâīêûАpпýдÌPXOаLṭfcжѕŹЉʻåŒÖÿḌřВhŐЗ-mTĺПœДșБlḍşиǃqüïŠЩxкйКMśȩСňäсМtɛNЦñЯюĎРəÚ4sFůçđËàŤĄĘыõùЭȇгūʼÅяОėồṛэÇÊUічȁЫwIЄÆЮz5ȋdĽyũò9ȉμaQǂűăöŁЁľŞųЏČ’αżæŃJAßшÄѯćáхфІkťќóѐuōґН̈ÜГÀKežÑďěôÎęźЕEтįјѝвSÍĂмƶVvYțЈЊR8ẹУHØуC1ŽoZÃiÁìWрЛоʕj360ÈїЃgĞıлŋÓãíł2ŕē"
  phoneme_symbols: ["'", '̽', 'ɓ', '̌', '̬', 'ʷ', 'ᵝ', 'ʙ', 'r', 'ǀ', 'è', 'ɜ', 'ʂ', '̻', 'ˢ', 'ɪ', 'ɐ', '̀', 'ɝ', '̚', 'ɹ', '̟', '̩', 'ˑ', 'ʊ', 'ʉ', 'ɾ', 'ɘ', 'é', 'ø', '-', '˨', '.', 'b', 'î', '?', 'ʐ', 'ð', 'n', 'ʝ', '̑', 'ɶ', 'ú', '͜', 'â', 'ʎ', 'ê', 'ɫ', 'û', 'p', 'θ', 'ʃ', '˦', '˧', 'ʦ', 'ý', '˕', 'ɲ', '̂', 'ɚ', 'f', 'ʏ', 'c', 'ɣ', 'ʍ', 'ʈ', 'h', '^', '˞', '∊', 'ɡ', 'ǎ', 'm', 'ᵻ', '̪', 'œ', '⁾', 'l', '︎', 'ǃ', 'q', 'ɭ', 'x', 'ʌ', 'ʒ', 'ä', 'ǐ', 'ʀ', '̊', 't', 'ɛ', '↗', 'ŏ', 'ə', 'ɵ', 'ɔ', '‿', 's', 'ɕ', '̥', 'ç', 'ĩ', 'à', 'ʁ', 'õ', '̃', 'ẽ', ',', '̆', 'ɒ', 'ù', 'ʲ', 'ħ', 'w', 'ʰ', 'z', 'ɻ', 'd', '̣', 'ũ', 'y', 'ò', 'ɟ', 'a', 'ˈ', 'ă', '⁽', 'æ', 'ɰ', '̍', '"', 'χ', 'β', 'á', 'k', '̯', 'ó', 'u', '̈', 'e', 'ǔ', 'ɯ', 'ě', 'ô', 'ˀ', 'ˣ', '̞', 'ɳ', 'ɮ', 'ɱ', 'v', 'ɸ', '̠', 'ǒ', 'ʳ', 'ạ', 'ɬ', '͡', 'ɽ', 'ε', 'ʔ', 'o', 'i', 'ì', 'ɨ', 'ʕ', '˗', '̺', 'j', 'ɤ', '̝', 'ɑ', 'g', 'ɥ', 'ʑ', 'ŋ', '́', '˥', 'ã', 'ˠ', 'í', 'ː', 'ɦ', 'ʋ']

  char_repeats: 3                # Number of grapheme character repeats to allow for mapping to longer phoneme sequences.
                                 # Set to 1 for autoreg_transformer.
  lowercase: false               # Whether to lowercase the grapheme input.
  n_val: 1000                    # Default number of validation data points if no explicit validation data is provided.


model:
  type: 'transformer'            # Whether to use a forward transformer or autoregressive transformer model.
                                 # Choices: ['transformer', 'autoreg_transformer']
  d_model: 512
  d_fft: 2048
  layers: 6
  dropout: 0.2
  heads: 8

training:

  # Hyperparams for learning rate and scheduler.
  # The scheduler is reducing the lr on plateau of phoneme error rate (tested every n_generate_steps).

  learning_rate: 0.0001              # Learning rate of Adam.
  warmup_steps: 10000                # Linear increase of the lr from zero to the given lr within the given number of steps.
  scheduler_plateau_factor: 0.5      # Factor to multiply learning rate on plateau.
  scheduler_plateau_patience: 10     # Number of text generations with no improvement to tolerate.
  batch_size: 64                    # Training batch size.
  batch_size_val: 32                 # Validation batch size.
  epochs: 500                        # Number of epochs to train.
  generate_steps: 10000              # Interval of training steps to generate sample outputs. Also, at this step the phoneme and word
                                     # error rates are calculated for the scheduler.
  validate_steps: 10000              # Interval of training steps to validate the model
                                     # (for the autoregressive model this is teacher-forced).
  checkpoint_steps: 100000           # Interval of training steps to save the model.
  n_generate_samples: 10             # Number of result samples to show on tensorboard.
  store_phoneme_dict_in_model: true  # Whether to store the raw phoneme dict in the model.
                                     # It will be loaded by the phonemizer object.
  ddp_backend: 'nccl'                # Backend used by Torch DDP
  ddp_host: 'localhost'              # Hostname used by Torch DDP
  ddp_post: '32355'                  # Port used by Torch DDP

